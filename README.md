<h1 align=center>Re-Thinking Inverse Graphics With Large Language Models</h1>

<p align=center><a href="https://kulits.github.io/">Peter Kulits</a><sup>*</sup>, <a href="https://ps.is.mpg.de/person/hfeng">Haiwen Feng</a><sup>*</sup>, <a href="https://wyliu.com/">Weiyang Liu</a>, <a href="https://is.mpg.de/~vabrevaya">Victoria Abrevaya</a>, <a href="https://ps.is.mpg.de/person/black">Michael J. Black</a></p>

<p align=center><a href="https://ig-llm.is.tue.mpg.de">[Project Page]</a></p>

Data and code coming soon.

<h2>Summary</h2>
<em>We present the Inverse-Graphics Large Language Model (<b>IG-LLM</b>) framework, a general approach to solving inverse-graphics problems. We instruction-tune an LLM to decode a visual (CLIP) embedding into graphics code that can be used to reproduce the observed scene using a standard graphics engine. Leveraging the broad reasoning abilities of LLMs, we demonstrate that our framework exhibits natural generalization across a variety of distribution shifts without the use of special inductive biases.</em>
<br/><br/>

![image](https://ig-llm.is.tue.mpg.de/media/upload/header.jpeg)
